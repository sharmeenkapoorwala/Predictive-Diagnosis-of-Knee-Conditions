---
output:
  pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

\begin{titlepage}
    \centering
    \vspace*{6cm}
    {\Huge \bfseries Predictive Diagnosis of Knee Conditions \par}
    \vskip 2cm
    {\Large Huiting Wu \par}
    {\Large Sharmeen Kapoorwala \par}
    \vskip 2cm
    {\large \today \par}
    \vfill
\end{titlepage}

\newpage



# Introduction

Describe the main research questions and goals of your data analysis and statistical modeling. 1-2 paragraphs should be sufficient.

Osteoporosis is the leading pathological disorder of bones after arthritis, affecting millions of people worldwide. The diagnosis of osteoporosis is done by Dual Energy X-ray Absorptiometry (DEXA).Inspired by this scenario, we have selected this database for the detection of osteoporosis. The database consists of clinical factors that are responsible for osteoporosis, with the T-score values obtained from the Quantitative Ultrasound System and Knee X-ray for each participant. 
The research question for our project is **"Can we predict if a patient has a normal or abnormal knee diagnosis (osteopenia or osteoporosis) based on basic patient data?"** and the goal of our data analysis and statistical modeling is to create a predictive model which is cost effective, can assist with early detection so it can help the doctors use prevention strategies (like diet changes, medications, or exercise programs) before major issues develop and last but not the least factor is it will be a support for Automated Systems i.e. it can be a first step towards AI-driven diagnostic tools that could eventually assist radiologists or orthopedic specialists.The analysis includes data wrangling, analyzing patterns and corelations and eventually applying statistical modeling or machine learing to predict the diagnosis for the patients. The ultimate goal is to support the development of flexible diagnostic tools that can be particularly helpful in areas where access to conventional bone health evaluations, such as DEXA scans, is restricted.


# Data Description

Briefly describe your data. What is the source? What are the response and potential predictor variables? What is the dimension (number of rows and columns)? In this section, also present and discuss relevant summary statistics and graphical displays of your data set (e.g., scatterplots, box plots). Be selective about the descriptive statistics that you decide to include.

The data was collected by Mendeley data and was published in August 2021. The important variables on which we are going to focus are diagnosis (which is the response variable and we have classified as 0,1. 0 is for normal and 1 is for osteopenia or osteoporosis), Gender, Age, Weight, Height, BMI, T-Score, Z-score, Menopause Age, Number of Pregnancies and Maximum Walking Distace covered in a day. We have a total of 240 observations out of which 36 patients has normal knee x-rays, 49 has osteoporosis and 154 has osteopenia and there are 27 variables of the dataset. 


```{r}
knitr::include_graphics("corelation.png")
knitr::include_graphics("boxplot.png")
```



# Methods and Results

Describe the methods used to estimate and select your regression model, and present the major modeling results (e.g., regression summary table, diagnostics plots, cross-validation results). Provide a concise description of the results and your interpretation.

AIC, BIC and decision tree was used for classification of model.

```{r}
knitr::include_graphics("tree_plot.png")
knitr::include_graphics("vip_plot.png")

knitr::include_graphics("Screenshot (127).png")
```



# Conclusion

Summarize the major conclusions and findings of your regression analysis. In this section, you can also provide limitations you encountered and ideas for future work.

# Code Appendix 

## Import the data

```{r libraries}
library(stringr)
library(readxl)
library(visdat)
library(dplyr)
library(car)
library(GGally)
library(rpart)
library(caret)
library(pROC)
library(rpart.plot) 
library(ggplot2)
library(knitr)
library(rsample)
library(vip)
```

```{r importing data}
knee <- read_excel("patient details.xlsx")
knee <- knee[1:(nrow(knee) - 3), ]
head(knee)
nrow(knee)
knee <- knee |> mutate(across(where(is.character), as.factor))
```

```{r boxplots}
knee |> select(`Maximum Walking distance (km)`) |> 
  table() |> hist(main = "Distribution of Maximum Walking distance",
                  xlab = "Maximum Walking distance(km)")

knee |> filter(Gender == "female") |> 
  select(`Menopause Age`) |> 
  boxplot(main = "Distribution Of Menopause Age for Female",
          ylab = "Menopause Age",
          xlab = "Gender in Female")

knee |> filter(Gender == "female") |> 
  select(`Number of Pregnancies`) |> 
  boxplot(main = "Distribution Of Number of Pregnancies for Female",
          ylab = "Number of Pregnancies",
          xlab = "Gender in Female")
```



```{r missing values}
colSums(is.na(knee))

naniar::gg_miss_var(knee)
vis_miss(knee)
```

## Clean the data

### Maximum Walking distance

* There is 1 missing value in `Maximum Walking distance (km)`. The distribution is right skewed. Impute it with the median.

```{r}
mwd_median <- median(knee$`Maximum Walking distance (km)`, na.rm = T)
knee <- knee |> mutate(
  MWD = ifelse(is.na(`Maximum Walking distance (km)`), mwd_median,
               `Maximum Walking distance (km)`)
) |> select(-`Maximum Walking distance (km)`)
```

```{r}
knee |> select(MWD) |> 
  table() |> hist(main = "Distribution of Maximum Walking distance(After Impute NA)",
                  xlab = "Maximum Walking distance(km)")
```

### Menopause Age

* Menopause typically occurs naturally between the ages of 45 and 55, with the average age being 51. It's defined as the point when a woman has not had a menstrual period for 12 consecutive months. 

```{r}
knee$Menopause_Age <- as.numeric(knee$`Menopause Age`)
knee <- knee |> select(-`Menopause Age`)
```

* The Menopause Age is right skewed for female. Impute the missing value with its median for female only. For male would be not apply. 

```{r}
female_median <- median(knee$Menopause_Age[knee$Gender == "female"], na.rm = TRUE)

knee <- knee  |> 
  mutate(Menopause_Age = case_when(
    Gender == "female" & is.na(Menopause_Age) ~ female_median,
    Gender == "male" & is.na(Menopause_Age) ~ NA_real_,  # keep as NA
    TRUE ~ Menopause_Age
  ))

knee |> filter(Gender == "female") |> 
  select(Menopause_Age) |> 
  boxplot(main = "Distribution Of Menopause Age for Female(After Impute NA)",
          ylab = "Menopause Age",
          xlab = "Gender in Female")
```

### Number of Pregnancies

* There is only one patient gender in male with number of pregnancies=4. Others are missing values.

```{r}
knee |> 
  filter(!is.na(`Number of Pregnancies`) & Gender == "male")
```

* Impute the gender male for number of pregnancies is 0.

```{r}
female_mean <- mean(knee$`Number of Pregnancies`[knee$Gender == "female"], 
                    na.rm = TRUE)

knee <- knee  |> 
  mutate(pregnancies = case_when(
    Gender == "female" & is.na(`Number of Pregnancies`) ~ female_mean,
    Gender == "male" & is.na(`Number of Pregnancies`) ~ 0,  # keep as NA
    TRUE ~ `Number of Pregnancies`
  )) |> 
  select(-`Number of Pregnancies`)

knee |> filter(Gender == "female") |> 
  select(pregnancies) |> 
  boxplot(main = "Distribution of Number of Pregnancies for Female
          (After Impute NA)",
          ylab = "Number of Pregnancies",
          xlab = "Female Patients")
```

### There are some categoriacal variables with only one level and some missing values

* `Alcoholic` only has the observation of "no". This variable will be dropped since is not helpful to put into the logistic regression.

* `Dialysis` is extremely imbalanced. There are only 1 observation with the level of "yes". The rest are "no". It is not stable in estimates.

* `Site` is not important. The data set is all about the knee.

### Other Variables

* `Occupation` with too many levels and most of the levels are only 1 observation. Need to be organized. Majority is house wife.


```{r}
occupation_corrections <- c(
  "h.wife" = "housewife"
)

knee <- knee |> 
  mutate(
     # lowercase and trim
    career_clean = tolower(trimws(Occupation)),
    
    # replace the names
    career_clean = str_replace_all(career_clean, occupation_corrections),
    
    # the missing value as "unknown"
    career_clean = ifelse(is.na(career_clean), "unknown", career_clean),
    
    # organize it more
    career = case_when(career_clean == "housewife" ~ "housewife",
      TRUE ~ "others"
    )
  ) |> select(-career_clean, -Occupation)
table(knee$career)
```

* `Daily Eating habits` same. Need to be organized. The main limits are Low/No Fat, Low Salt, Low/No Protein, Low Sugar, No Sour Food. Organize it as 2 levels Normal and Limited. The missing value as normal(there are 2).

```{r}
knee <- knee |> 
  mutate(
    eating_clean = tolower(trimws(`Daily Eating habits`)),
    eating_habit = ifelse(
      eating_clean == "normal", "normal", "limited"
    )
  ) |>
  select(-eating_clean, -`Daily Eating habits`)
table(knee$eating_habit)
```

* `Obesity` combine over weight and overweight.

```{r}
knee <- knee |> mutate(
  obesity = ifelse(Obesity == "overweight", "over weight", Obesity)
) |> select(-Obesity)
table(knee$obesity)
```

* Clean up `History of Fracture` into injuries in lower body, upper body, other, or no injury

```{r}
knee <- knee |> 
  mutate(
    injury_type = `History of Fracture`,
    # Clean up and categorize injuries into main parts
    injury_part = case_when(
      str_detect(injury_type, "leg") ~ "leg",
      str_detect(injury_type, "foot") ~ "foot",
      str_detect(injury_type, "arm") ~ "arm",
      str_detect(injury_type, "wrist") ~ "wrist",
      str_detect(injury_type, "shoulder") ~ "shoulder",
      str_detect(injury_type, "hip") ~ "hip",
      str_detect(injury_type, "no") ~ "no injury",
      str_detect(injury_type, "knee") ~ "knee",
      str_detect(injury_type, "head") ~ "head",
      str_detect(injury_type, "neck") ~ "neck",
      TRUE ~ "Other"
    ),
    
    # Categorizing into lower body, upper body, and fractures
    injury = case_when(
      injury_part %in% c("leg", "foot", "hip", "knee") ~ "Lower Body",
      injury_part %in% c("arm", "wrist", "shoulder", "head", "neck") ~ "Upper Body",
      injury_part == "Other" ~ "Other",
      injury_part == "no injury" ~ "no injury",
      TRUE ~ "Fractures"
    )
  ) |> select(-injury_type, -injury_part, -`History of Fracture`)
table(knee$injury)
```

* Clean `Medical History` into yes for having medical history and no for not having medical history

```{r}
knee <- knee |> mutate(
  medical_hist = ifelse(`Medical History` %in% c("no", "normal"), "no", "yes")
) |> select(-`Medical History`)
table(knee$medical_hist)
```

### Rename the variables and filter out not interesting variables

```{r}
knee <- knee |> mutate(across(where(is.character), as.factor)) |> 
  select(-`Patient Id`, -Alcoholic, -Site, -S.No) |> 
  rename(BMI = `BMI:`,
         dialysis = `Dialysis:`,
         joint_pain = `Joint Pain:`)
```

## Visualization

```{r}
# Create a binary response with yes or no (1, 0)
knee_clean <- knee |> mutate(
  dummy_diagnosis = ifelse(Diagnosis == "normal", 0, 1),
  dummy_diagnosis = as.factor(dummy_diagnosis),
)
str(knee_clean)

```
### Corelation

```{r message=FALSE, fig.width=15, fig.height=10}
ggpairs(
  knee |> select(Diagnosis, where(is.numeric), -Menopause_Age),
  aes(color = Diagnosis),
  upper = list(continuous = wrap("cor", size = 4)), 
  lower = list(continuous = wrap("points", alpha = 0.6)),
  diag = list(continuous = wrap("densityDiag", alpha = 0.5)),
  legend = 1
) + 
  scale_color_brewer(palette = "Set2") +
  theme_minimal()
```

### Diagnoses comparing with gender male excluding [menopause age, number of pregnancies] 

```{r}
knee_clean |> group_by(Diagnosis) |> 
  ggplot(aes(x = Diagnosis, fill = Gender)) +
  geom_bar(position = "dodge", col = "black") +
  labs(title = "Diagnosis Distribution among male 
       and female patients",
       y = "Frequency") + 
  theme_classic()
```

```{r}
knee_male <- knee_clean |>
  filter(Gender == "male") |>
  group_by(Diagnosis) |>
  select(-Menopause_Age) |>
    count(name = "Male Patients")
knee_male
knee_female <- knee_clean |>
  filter(Gender == "female") |>
  group_by(Diagnosis) |>
    count(name = "Female Patients")
knee_female

```




## Logistic Regression

```{r}
knee_model <- knee_clean |> 
  select(-Diagnosis, -Menopause_Age, -dialysis, 
         -`T-score Value`, -`Z-Score Value`, -obesity) |> na.omit()

full <- glm(dummy_diagnosis ~ ., data = knee_model, family = binomial)
summary(full)

null <- glm(dummy_diagnosis ~ 1, data = knee_model, family = binomial)

```
**AIC**

```{r}
step(full, trace = 0)

select_aic <- glm(dummy_diagnosis ~ Age + `Weight (KG)` + Diabetic + 
    BMI + pregnancies + career + medical_hist, family = binomial, 
    data = knee_model)
summary(select_aic)
```

**BIC**

```{r}
step(full, trace = 0, k = log(nrow(knee_model)))
```

```{r}
select_bic <- glm(dummy_diagnosis ~ Age + pregnancies, family = binomial, 
    data = knee_model)
summary(select_bic)
```

```{r}
AIC(null, full, select_bic, select_aic)
BIC(null, full, select_bic, select_aic)
```

## Cross Validation: check the logistic model

**BIC Model**

```{r message=FALSE}
set.seed(333)
n <- nrow(knee_model)
floor(0.7*n)

# split into training data and testing data
train <- sample(1:n, 166)

# fit the model with training data
glm_train <- glm(dummy_diagnosis ~ Age + pregnancies, family = binomial, 
    data = knee_model, subset = train) # chose the smallest bic model

# summary
summary(glm_train)

# test set
test <- knee_model[-train, ]

# prediction on test set
pred_prob <- predict(glm_train, newdata = test, type = "response")

# classify the prediction
length(pred_prob)

class_preds <- rep(0, 72)
class_preds[pred_prob > 0.5] <- 1

# confusion matrix
addmargins(table(prediction = class_preds, actual = test$dummy_diagnosis))

# accuracy
(9 + 57)/72 # 0.9166667

# sensitivity
57/61 # 0.9344262

# specificity
9/11 # 0.8181818

# ROC curve
roc_obj <- roc(test$dummy_diagnosis, pred_prob)
plot(1 - roc_obj$specificities, roc_obj$sensitivities, type = "l",
     xlab = "1 - Specificity", ylab = "Sensitivity")

abline(0, 1, lty=2)
points(x = 2/11, y = 60/61, col = "red", pch = 19)


# ROC Curve
roc_curve <- roc(test$dummy_diagnosis, pred_prob)
plot(roc_curve, main = "ROC Curve for BIC Model", col = "blue", lwd = 2)


# AUC
auc(roc_obj) # 0.9575
```
**AIC model**

```{r message=FALSE}
set.seed(333)
n <- nrow(knee_model)
floor(0.7*n)

# split into training data and testing data
train <- sample(1:n, 166)

# fit the model with training data
glm_train <- glm(dummy_diagnosis ~ Age + `Weight (KG)` + Diabetic + 
    BMI + pregnancies + career + medical_hist, family = binomial, 
    data = knee_model)

# summary
summary(glm_train)

# test set
test <- knee_model[-train, ]

# prediction on test set
pred_prob <- predict(glm_train, newdata = test, type = "response")

# classify the prediction
length(pred_prob)

class_preds <- rep(0, 72)
class_preds[pred_prob > 0.5] <- 1

# confusion matrix
addmargins(table(prediction = class_preds, actual = test$dummy_diagnosis))

# accuracy
(10+58)/72 # 0.9444444

# sensitivity
58/61 # 0.9508197

# specificity
10/11 # 0.9090909



# ROC curve
roc_obj <- roc(test$dummy_diagnosis, pred_prob)
plot(1 - roc_obj$specificities, roc_obj$sensitivities, type = "l",
     xlab = "1 - Specificity", ylab = "Sensitivity")
abline(0, 1, lty=2)
points(x = 2/11, y = 61/61, col = "red", pch = 19)

# ROC Curve
roc_curve <- roc(test$dummy_diagnosis, pred_prob)
plot(roc_curve, main = "ROC Curve for AIC Model", col = "blue", lwd = 2)


# AUC
auc(roc_obj) # 0.9434
```

## Desicion Tree

```{r}
# Split data into training and testing sets
set.seed(333)

data_split <- knee_model |> initial_split(prop = 0.7)
train_data <- data_split |> training()
test_data <- data_split |> testing()

# Fit the Decision Tree Model
tree_model <- rpart(dummy_diagnosis ~ ., data = train_data, method = "class")

# Predict on the test set
tree_pred <- predict(tree_model, test_data, type = "class")
tree_pred_prob <- predict(tree_model, test_data, type = "prob")

# Confusion Matrix
conf_matrix <- table(test_data$dummy_diagnosis, tree_pred)

addmargins(conf_matrix)

# Calculate Accuracy, Sensitivity, and Specificity

(4 + 59)/72 # 0.875
59/66 # 0.8939394
4/6 # 0.6666667

# ROC Curve
roc_curve <- roc(test_data$dummy_diagnosis, tree_pred_prob[,2])
plot(roc_curve, main = "ROC Curve for Decision Tree", col = "blue", lwd = 2)

# Calculate AUC (Area Under the Curve)
auc_value <- auc(roc_curve)
auc_value #  0.8979

# Variable Importance
var_imp <- tree_model$variable.importance
print(var_imp)

v_plot <- vip(tree_model) + geom_col(fill = "khaki", col = "black") + 
  theme_minimal() +
  labs(title = "Important Variables in Decision Tree Model")
v_plot

# Plot the Decision Tree
rpart.plot(tree_model, type = 3, main = "Decision Tree", digits = 1)
```

```{r}
knee_tree <- knee_clean |> 
  select(-dummy_diagnosis, -dialysis, 
         -`T-score Value`, -`Z-Score Value`) |> na.omit()
# Split data into training and testing sets
set.seed(632)

data_split <- knee_tree |> initial_split(prop = 0.7)
train_data <- data_split |> training()
test_data <- data_split |> testing()

# Fit the Decision Tree Model
tree_model <- rpart(Diagnosis ~ ., data = train_data, method = "class")

# Predict on the test set
tree_pred <- predict(tree_model, test_data, type = "class")
tree_pred_prob <- predict(tree_model, test_data, type = "prob")

# Confusion Matrix
conf_matrix <- table(test_data$Diagnosis, tree_pred)

addmargins(conf_matrix)

# ROC Curve
roc_curve <- roc(test_data$Diagnosis, tree_pred_prob[,2])
plot(roc_curve, main = "ROC Curve for Decision Tree", col = "blue", lwd = 2)

# Calculate AUC (Area Under the Curve)
auc_value <- auc(roc_curve)
auc_value # 0.7418

# Variable Importance
var_imp <- tree_model$variable.importance
print(var_imp)

v_plot <- vip(tree_model) + geom_col(fill = "khaki", col = "black") + 
  theme_minimal() +
  labs(title = "Important Variables in Decision Tree Model")
v_plot

# Plot the Decision Tree
rpart.plot(tree_model, type = 3, main = "Decision Tree", digits = 1)
```

